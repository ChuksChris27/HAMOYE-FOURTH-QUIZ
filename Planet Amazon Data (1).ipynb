{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77163a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44bca9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lab = pd.read_csv('train_v2.csv')\n",
    "train_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df565265",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_v2.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number =10\n",
    "img = io.imread('https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg'.format(image_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a28790",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c62c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check value_counts()\n",
    "train_lab.tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdd34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique = set()\n",
    "def append_labels(tags):\n",
    "    for tag in tags.split():\n",
    "        unique.add(tag)\n",
    "\n",
    "train_labs = train_lab.copy()\n",
    "train_labs['tags'].apply(append_labels)\n",
    "unique = list(unique)\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6596df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding '.jpg' extension to 'image_name'\n",
    "train_labs['image_name'] = train_labs['image_name'].apply(lambda x: '{}.jpg'.format(x)) \n",
    "train_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9de20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = list(train_labs.columns[2:]) # storing the tags column names as a variable\n",
    "\n",
    "# initializing an image generator with some data augumentation\n",
    "image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# loading images from dataframe\n",
    "X = image_gen.flow_from_dataframe(dataframe=train_labs, \\\n",
    "        directory='https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg', x_col='image_name', y_col=y_col, \\\n",
    "       target_size=(64, 64), class_mode='raw', seed=1, batch_size=64, validate_filenames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(ytrue , ypred, beta=2, epsilon=1e-4):\n",
    "    beta_squarred = beta**2\n",
    "\n",
    "    ytrue = tf.cast(ytrue, tf.float32)\n",
    "    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "        \n",
    "    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n",
    "    fp = tf.reduce_sum(ypred, axis=1) - tp\n",
    "    fn = tf.reduce_sum(ytrue, axis=1) - tp\n",
    "    \n",
    "    precision = tp/(tp+fp+epsilon)\n",
    "    recall = tp/(tp+fn+epsilon)\n",
    "    \n",
    "    fb = (1+beta_squarred)*precision*recall / (beta_squarred*precision + recall + epsilon)\n",
    "    return fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_acc(ytrue , ypred, epsilon=1e-4):\n",
    "    \n",
    "    ytrue = tf.cast(ytrue, tf.float32)\n",
    "    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "    \n",
    "    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n",
    "    fp = tf.reduce_sum(ypred, axis=1) - tp\n",
    "    fn = tf.reduce_sum(ytrue, axis=1) - tp\n",
    "    \n",
    "    ytrue = tf.cast(ytrue, tf.bool)\n",
    "    ypred = tf.cast(ypred, tf.bool)\n",
    "    \n",
    "    tn = tf.reduce_sum(tf.cast(tf.logical_not(ytrue), tf.float32) * tf.cast(tf.logical_not(ypred), tf.float32),\\\n",
    "                       axis=1)\n",
    "    \n",
    "    return (tp+tn)/(tp+tn+fp+fn+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831fc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    in_shape=(64, 64, 3)\n",
    "    out_shape=17\n",
    "\n",
    "    # load mannequin\n",
    "\n",
    "    mannequin = VGG16(include_top=False, input_shape=in_shape)\n",
    "\n",
    "    # mark loaded layers as not trainable\n",
    "\n",
    "    for layer in mannequin.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # enable final vgg block to be trainable\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv1\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv2\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv3\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_pool\").trainable = True\n",
    "\n",
    "    # add new classifier layers\n",
    "\n",
    "    flat1 = Flatten()(mannequin.layers[-1].output)\n",
    "\n",
    "    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n",
    "\n",
    "    output = Dense(out_shape, activation=\"sigmoid\")(class1)\n",
    "\n",
    "    # outline new mannequin\n",
    "\n",
    "    mannequin = Model(inputs=mannequin.inputs, outputs=output)\n",
    "\n",
    "    # compile mannequin\n",
    "\n",
    "    choose = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    mannequin.compile(optimizer=choose, loss=\"binary_crossentropy\", metrics=[fbeta, multi_label_acc])\n",
    "    \n",
    "    return mannequin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_check_point = ModelCheckpoint(filepath='best_model.hdf5', monitor='val_fbeta',mode='max', save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,validation_split=0.2)\n",
    "\n",
    "# generating the 80% training image data\n",
    "train_gen = train_image_gen.flow_from_dataframe(dataframe=train_labs, \\\n",
    "        directory='https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg', x_col='image_name', y_col=y_col, \\\n",
    "       target_size=(64, 64), class_mode='raw', seed=0, batch_size=64, subset='training', validate_filenames=False)\n",
    "\n",
    "# generating the 20% validation image data\n",
    "val_gen = train_image_gen.flow_from_dataframe(dataframe=train_labs, \\\n",
    "        directory='https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg', x_col='image_name', y_col=y_col, \\\n",
    "       target_size=(64,64), class_mode='raw', seed=0, batch_size=64, subset='validation', validate_filenames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f04178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting step size for training and validation image data\n",
    "step_train_size = int(np.ceil(train_gen.samples / train_gen.batch_size))\n",
    "step_val_size = int(np.ceil(val_gen.samples / train_gen.batch_size))\n",
    "step_train_size+step_val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b249cd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list =[]\n",
    "\n",
    "for tag_str in train_labs.tags.values:\n",
    "    labels =tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)\n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e81554",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_list:\n",
    "    train_labs[label] =train_labs['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "# Display head\n",
    "train_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189622b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def make_cooccurence_matrix(labels):\n",
    "    numeric_df = train_labs[labels]; \n",
    "    c_matrix = numeric_df.T.dot(numeric_df)\n",
    "    sns.heatmap(c_matrix)\n",
    "    return c_matrix\n",
    "    \n",
    "# Compute the co-ocurrence matrix\n",
    "make_cooccurence_matrix(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded16bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number =10\n",
    "imgs = io.imread('https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/agg1.jpg'.format(image_number))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ee592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from os import listdir\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_mapping(labels_df):\n",
    "    \n",
    "    labels = set()\n",
    "    for i in range(len(labels_df)):\n",
    "        # convert spaced separated tags into an array of tags\n",
    "        tags = labels_df['tags'][i].split(' ')\n",
    "        # add tags to the set of known labels\n",
    "        labels.update(tags)\n",
    "    # convert set of labels to a list to list\n",
    "    labels = list(labels)\n",
    "    labels.sort()\n",
    " # dict that maps labels to integers, and the reverse\n",
    "    labels_map = { labels [i]:i for i in range(len(labels))}\n",
    "    inv_labels_map = {i: labels [i] for i in range(len(labels))}\n",
    "    return labels_map, inv_labels_map\n",
    "\n",
    "\n",
    "\n",
    "def create_file_mapping(train_data):\n",
    "    mapping = dict()\n",
    "    for i in range(len(labels_df)):\n",
    "        name, tags = train_data['image_name'][i], labels_df['tags'][i]\n",
    "        mapping[name] = tags.split(' ')\n",
    "        \n",
    "    return mapping\n",
    "\n",
    "\n",
    "def one_hot_encode(tags,mapping):\n",
    "    \n",
    "    # create empty vector\n",
    "    encoding = zeros(len(mapping), dtype='uint8')\n",
    "    # mark 1 for each tag in the vector\n",
    "    for tag in tags:\n",
    "        encoding[mapping[tag]] = 1\n",
    "    return encoding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(path, file_mapping, tag_mapping):\n",
    "    photos, targets = list(), list()\n",
    "    # enumerate files in the directory\n",
    "    for filename in listdir(folder):\n",
    "        # load image\n",
    "        photo = load_img(path + filename, target_size=(64,64))\n",
    "        # convert to numpy array\n",
    "        photo = img_to_array(photo, dtype='uint8')\n",
    "        # get tags\n",
    "        tags = file_mapping[filename[:-4]]\n",
    "        # one hot encode tags\n",
    "        target = one_hot_encode(tags, tag_mapping)\n",
    "        # store\n",
    "        photos.append(photo)\n",
    "        targets.append(target)\n",
    "    X = asarray(photos, dtype='uint8')\n",
    "    y = asarray(targets, dtype='uint8')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a660899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'train_v2.csv'\n",
    "labels_df = pd.read_csv('train_v2.csv', encoding='latin1')\n",
    "\n",
    "# create a mapping of tags to integers\n",
    "mapping, inv_mapping = create_tag_mapping(labels_df)\n",
    "print(len(mapping))\n",
    "print(mapping)\n",
    "\n",
    "# create a mapping of tags to integers\n",
    "tag_mapping, _ = create_tag_mapping(labels_df)\n",
    "\n",
    "# create a mapping of filenames to tag lists\n",
    "file_mapping = create_file_mapping(labels_df)\n",
    "\n",
    "# load the jpeg images\n",
    "folder = 'https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg'\n",
    "X, y = load_dataset(folder, file_mapping, tag_mapping)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# save both arrays to one file in compressed format\n",
    "savez_compressed('planet_data.npz', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a010016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D,Flatten,MaxPooling2D,Dropout,Dense,BatchNormalization,SpatialDropout2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "data = np.load('./planet_data.npz')\n",
    "X,y =data['arr_0'],data['arr_1']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # clip predictions\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate elements\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf572c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "train_datagen.mean = [123.68, 116.779, 103.939]\n",
    "test_datagen.mean = [123.68, 116.779, 103.939]\n",
    "train_datagen.fit(X_train)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "train_it = train_datagen.flow(X_train, Y_train, batch_size=128)\n",
    "\n",
    "test_it = test_datagen.flow(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D,Flatten,MaxPooling2D,Dropout,Dense,BatchNormalization,SpatialDropout2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    in_shape=(64, 64, 3)\n",
    "    out_shape=17\n",
    "    \n",
    "    #load mannequin\n",
    "    mannequin = VGG16(include_top=False, input_shape=in_shape)\n",
    "\n",
    "    # mark loaded layers as not trainable\n",
    "\n",
    "    for layer in mannequin.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # enable final vgg block to be trainable\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv1\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv2\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_conv3\").trainable = True\n",
    "\n",
    "    mannequin.get_layer(\"block5_pool\").trainable = True\n",
    "\n",
    "    # add new classifier layers\n",
    "\n",
    "    flat1 = Flatten()(mannequin.layers[-1].output)\n",
    "\n",
    "    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n",
    "\n",
    "    output = Dense(out_shape, activation=\"sigmoid\")(class1)\n",
    "\n",
    "    # outline new mannequin\n",
    "\n",
    "    mannequin = Model(inputs=mannequin.inputs, outputs=output)\n",
    "\n",
    "    # compile mannequin\n",
    "\n",
    "    choose = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    mannequin.compile(optimizer=choose, loss=\"binary_crossentropy\", metrics=[fbeta])\n",
    "    \n",
    "    return mannequin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "# cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "save_best_check_point = ModelCheckpoint(filepath='our_model.hdf5', monitor='val_fbeta', mode='max', save_best_only=True, save_weights_only=True)\n",
    "# checkpoint = ModelCheckpoint(filepath='weights/weights.hdf5',monitor='val_fbeta', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_fbeta', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "# fit model\n",
    "# history = full_model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "mannequin.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=10,callbacks=[save_best_check_point])\n",
    "\n",
    "\n",
    "# evaluate model\n",
    "loss, fbeta = mannequin.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model() # building a sequential model for testing\n",
    "\n",
    "#loading in the weights of the trained model\n",
    "model2.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c86194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = sample_submission_df.copy()\n",
    "sample_submission['image_name'] = sample_submission['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_df = sample_submission.iloc[:40669]['image_name'].reset_index().drop('index', axis=1)\n",
    "test1_df.head()\n",
    "test1_df.shape\n",
    "# initializing an image data generator object for the first 40669 images in the sample submission dataframe\n",
    "test_image_gen1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# generating the image data for the first 40669 images in the sample submission dataframe\n",
    "test_gen1 = test_image_gen1.flow_from_dataframe(dataframe=test1_df, directory='https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg', x_col='image_name', y_col=None, batch_size=128, shuffle=False, class_mode=None, target_size=(64,64), validate_filenames=False)\n",
    "\n",
    "# setting the step size for the testing set for the first 40669 images in the sample submission dataframe\n",
    "step_test_size1 = int(np.ceil(test_gen1.samples / test_gen1.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bbcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen1.reset() # reseting the generator to be sure of avoiding shuffling\n",
    "pred1 = model2.predict(test_gen1, steps=step_test_size1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names1 = test_gen1.filenames # storing the filenames (images names) of the first 40669 images names in \n",
    "                                       # the sample submission dataframe as ordered in the prediction as a \n",
    "                                       # variable\n",
    "\n",
    "# converting the predictions of the first 40669 to tag names\n",
    "pred_tags1 = pd.DataFrame(pred1)\n",
    "pred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n",
    "\n",
    "# converting the predictions of the first 40669 to a dataframe\n",
    "result1 = pd.DataFrame({'image_name': test_file_names1, 'tags': pred_tags1})\n",
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = sample_submission.iloc[40669:]['image_name'].reset_index().drop('index', axis=1)\n",
    "test2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b715b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_gen2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# generating the image data for the remaining images in the sample submission dataframe\n",
    "test_gen2 = test_image_gen2.flow_from_dataframe(dataframe=test2_df, \\\n",
    "            directory='https://storage.googleapis.com/kaggle-competitions/kaggle/6322/media/habitation1.jpg', x_col='image_name', \\\n",
    "            y_col=None, batch_size=128, shuffle=False, class_mode=None, target_size=(64,64), validate_filename=False)\n",
    "\n",
    "# setting the step size for the testing set for the remaining images in the sample submission dataframe\n",
    "step_test_size2 = int(np.ceil(test_gen2.samples / test_gen2.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen2.reset() # reseting the generator to be sure of avoiding shuffling\n",
    "pred2 = model2.predict(test_gen2, steps=step_test_size2, verbose=1)\n",
    "\n",
    "test_file_names2 = test_gen2.filenames # storing the filenames (images names) of the remaining images names in \n",
    "                                       # the sample submission dataframe as ordered in the prediction as a \n",
    "                                       # variable\n",
    "\n",
    "# converting the predictions of the remaining images to tag names\n",
    "pred_tags2 = pd.DataFrame(pred2)\n",
    "pred_tags2 = pred_tags2.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n",
    "\n",
    "# converting the predictions of the remaining to a dataframe\n",
    "\n",
    "len(test_file_names2)\n",
    "len(pred_tags2)\n",
    "result2 = pd.DataFrame({'image_name': test_file_names2, 'tags': pred_tags2})\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546cb658",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.concat([result1, result2]) # concatenate the predictions of the test.jpg and \n",
    "                                             # test-additional.jpg into a single dataframe\n",
    "\n",
    "final_result = final_result.reset_index().drop('index', axis=1) # reseting the index of the dataframe so it \n",
    "                                                                # matches that of sample submission datafarme\n",
    "\n",
    "print(final_result.shape)\n",
    "final_result.head()\n",
    "\n",
    "assert sum(sample_submission['image_name'] == final_result['image_name']) == 61191\n",
    "# removing the .jpg extension from 'iamge_name' column\n",
    "final_result['image_name'] = final_result['image_name'].apply(lambda x: x[:-4])\n",
    "final_result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ada1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('final_submission.csv', index=False) # saving the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad1dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
